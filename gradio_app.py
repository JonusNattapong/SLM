import gradio as gr
import torch
import os
from inference import ThaiSLMInference


class GradioInterface:
    """Gradio web interface for Thai SLM"""
    
    def __init__(self, model_path: str = "./thai_slm_moe_model"):
        try:
            self.inference = ThaiSLMInference(model_path)
            self.model_loaded = True
        except Exception as e:
            print(f"Error loading model: {e}")
            self.model_loaded = False
    
    def generate_text(self, 
                     prompt: str,
                     max_length: int = 150,
                     temperature: float = 0.8,
                     top_k: int = 50,
                     top_p: float = 0.9) -> str:
        """Generate text with parameters"""
        
        if not self.model_loaded:
            return "‚ùå Model not loaded. Please train the model first."
        
        if not prompt.strip():
            return "‚ö†Ô∏è Please enter a prompt."
        
        try:
            generated = self.inference.generate_text(
                prompt=prompt,
                max_length=max_length,
                temperature=temperature,
                top_k=top_k,
                top_p=top_p,
                do_sample=True
            )
            return generated
        except Exception as e:
            return f"‚ùå Error generating text: {str(e)}"
    
    def create_interface(self):
        """Create Gradio interface"""
        
        # Custom CSS
        css = """
        .gradio-container {
            font-family: 'Noto Sans Thai', sans-serif;
        }
        .title {
            text-align: center;
            color: #2E86AB;
            margin-bottom: 20px;
        }
        """
        
        with gr.Blocks(css=css, title="Thai SLM MoE") as interface:
            
            gr.Markdown(
                """
                # üáπüá≠ Thai Small Language Model with Mixture of Experts
                
                ‡∏†‡∏≤‡∏©‡∏≤‡πÑ‡∏ó‡∏¢ Small Language Model (SLM) ‡∏û‡∏£‡πâ‡∏≠‡∏° Mixture of Experts (MoE) Architecture
                
                ‡πÉ‡∏™‡πà‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÉ‡∏´‡πâ‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏ï‡πà‡∏≠‡πÄ‡∏ï‡∏¥‡∏°‡∏´‡∏£‡∏∑‡∏≠‡∏ï‡∏≠‡∏ö‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°
                """,
                elem_classes=["title"]
            )
            
            if not self.model_loaded:
                gr.Markdown(
                    """
                    ‚ö†Ô∏è **Model not found!**
                    
                    Please train the model first by running:
                    ```bash
                    python train.py
                    ```
                    """,
                    elem_classes=["warning"]
                )
            
            with gr.Row():
                with gr.Column(scale=2):
                    # Input section
                    prompt_input = gr.Textbox(
                        label="üìù ‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏ï‡πâ‡∏ô (Prompt)",
                        placeholder="‡πÄ‡∏ä‡πà‡∏ô: ‡∏õ‡∏£‡∏∞‡πÄ‡∏ó‡∏®‡πÑ‡∏ó‡∏¢‡∏°‡∏µ‡∏à‡∏±‡∏á‡∏´‡∏ß‡∏±‡∏î...",
                        lines=3,
                        max_lines=5
                    )
                    
                    # Parameters section
                    with gr.Accordion("‚öôÔ∏è ‡∏û‡∏≤‡∏£‡∏≤‡∏°‡∏¥‡πÄ‡∏ï‡∏≠‡∏£‡πå‡∏Å‡∏≤‡∏£‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°", open=False):
                        max_length = gr.Slider(
                            minimum=10,
                            maximum=500,
                            value=150,
                            step=10,
                            label="‡∏Ñ‡∏ß‡∏≤‡∏°‡∏¢‡∏≤‡∏ß‡∏™‡∏π‡∏á‡∏™‡∏∏‡∏î (Max Length)"
                        )
                        
                        temperature = gr.Slider(
                            minimum=0.1,
                            maximum=2.0,
                            value=0.8,
                            step=0.1,
                            label="‡∏≠‡∏∏‡∏ì‡∏´‡∏†‡∏π‡∏°‡∏¥ (Temperature)"
                        )
                        
                        top_k = gr.Slider(
                            minimum=1,
                            maximum=100,
                            value=50,
                            step=1,
                            label="Top-K"
                        )
                        
                        top_p = gr.Slider(
                            minimum=0.1,
                            maximum=1.0,
                            value=0.9,
                            step=0.05,
                            label="Top-P"
                        )
                    
                    generate_btn = gr.Button(
                        "üöÄ ‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°",
                        variant="primary",
                        size="lg"
                    )
                
                with gr.Column(scale=2):
                    # Output section
                    output_text = gr.Textbox(
                        label="üìÑ ‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡∏ó‡∏µ‡πà‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏Ç‡∏∂‡πâ‡∏ô",
                        lines=10,
                        max_lines=15,
                        interactive=False
                    )
            
            # Examples section
            with gr.Accordion("üí° ‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏Å‡∏≤‡∏£‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô", open=True):
                examples = [
                    ["‡∏õ‡∏£‡∏∞‡πÄ‡∏ó‡∏®‡πÑ‡∏ó‡∏¢‡∏°‡∏µ‡∏à‡∏±‡∏á‡∏´‡∏ß‡∏±‡∏î"],
                    ["‡∏ß‡∏¥‡∏ó‡∏¢‡∏≤‡∏®‡∏≤‡∏™‡∏ï‡∏£‡πå‡πÅ‡∏•‡∏∞‡πÄ‡∏ó‡∏Ñ‡πÇ‡∏ô‡πÇ‡∏•‡∏¢‡∏µ"],
                    ["‡∏Å‡∏≤‡∏£‡∏®‡∏∂‡∏Å‡∏©‡∏≤‡πÉ‡∏ô‡∏¢‡∏∏‡∏Ñ‡∏î‡∏¥‡∏à‡∏¥‡∏ó‡∏±‡∏•"],
                    ["‡∏≠‡∏≤‡∏´‡∏≤‡∏£‡πÑ‡∏ó‡∏¢‡∏ó‡∏µ‡πà‡∏°‡∏µ‡∏ä‡∏∑‡πà‡∏≠‡πÄ‡∏™‡∏µ‡∏¢‡∏á"],
                    ["‡∏õ‡∏£‡∏∞‡∏ß‡∏±‡∏ï‡∏¥‡∏®‡∏≤‡∏™‡∏ï‡∏£‡πå‡∏Ç‡∏≠‡∏á‡πÑ‡∏ó‡∏¢"],
                    ["‡∏®‡∏¥‡∏•‡∏õ‡∏∞‡πÅ‡∏•‡∏∞‡∏ß‡∏±‡∏í‡∏ô‡∏ò‡∏£‡∏£‡∏°‡πÑ‡∏ó‡∏¢"],
                    ["‡πÄ‡∏®‡∏£‡∏©‡∏ê‡∏Å‡∏¥‡∏à‡πÑ‡∏ó‡∏¢‡πÉ‡∏ô‡∏≠‡∏ô‡∏≤‡∏Ñ‡∏ï"]
                ]
                
                gr.Examples(
                    examples=examples,
                    inputs=[prompt_input],
                    label="‡∏Ñ‡∏•‡∏¥‡∏Å‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÉ‡∏ä‡πâ‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á"
                )
            
            # Model info section
            with gr.Accordion("‚ÑπÔ∏è ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÇ‡∏°‡πÄ‡∏î‡∏•", open=False):
                gr.Markdown(
                    """
                    ### Architecture Details:
                    - **Model Type**: Small Language Model with Mixture of Experts
                    - **Language**: Thai (‡πÑ‡∏ó‡∏¢)
                    - **Training Data**: ZombitX64/Wikipedia-Thai
                    - **Tokenizer**: Custom ByteLevelBPE for Thai
                    - **Features**: RoPE, SwiGLU, MoE layers
                    
                    ### Parameters:
                    - **Temperature**: ‡∏Ñ‡∏ß‡∏ö‡∏Ñ‡∏∏‡∏°‡∏Ñ‡∏ß‡∏≤‡∏°‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏™‡∏£‡∏£‡∏Ñ‡πå (‡∏™‡∏π‡∏á = ‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏™‡∏£‡∏£‡∏Ñ‡πå‡∏°‡∏≤‡∏Å‡∏Ç‡∏∂‡πâ‡∏ô)
                    - **Top-K**: ‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡∏Ñ‡∏≥‡∏ó‡∏µ‡πà‡∏û‡∏¥‡∏à‡∏≤‡∏£‡∏ì‡∏≤ (‡∏ô‡πâ‡∏≠‡∏¢ = ‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡πÄ‡∏â‡∏û‡∏≤‡∏∞‡∏Ñ‡∏≥‡∏ó‡∏µ‡πà‡∏ô‡πà‡∏≤‡∏à‡∏∞‡πÄ‡∏õ‡πá‡∏ô‡πÑ‡∏õ‡πÑ‡∏î‡πâ‡∏°‡∏≤‡∏Å)
                    - **Top-P**: ‡∏™‡∏±‡∏î‡∏™‡πà‡∏ß‡∏ô‡∏Ñ‡∏ß‡∏≤‡∏°‡∏ô‡πà‡∏≤‡∏à‡∏∞‡πÄ‡∏õ‡πá‡∏ô‡∏™‡∏∞‡∏™‡∏° (‡∏ô‡πâ‡∏≠‡∏¢ = ‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡∏Ñ‡∏≥‡∏ó‡∏µ‡πà‡πÅ‡∏ô‡πà‡∏ô‡∏≠‡∏ô‡∏°‡∏≤‡∏Å‡∏Ç‡∏∂‡πâ‡∏ô)
                    """
                )
            
            # Event handlers
            generate_btn.click(
                fn=self.generate_text,
                inputs=[prompt_input, max_length, temperature, top_k, top_p],
                outputs=[output_text]
            )
            
            # Auto-generate on example click
            for example in examples:
                prompt_input.change(
                    fn=lambda x: x if x else "",
                    inputs=[prompt_input],
                    outputs=[]
                )
        
        return interface
    
    def launch(self, share: bool = False, port: int = 7860):
        """Launch the interface"""
        interface = self.create_interface()
        interface.launch(
            share=share,
            server_port=port,
            server_name="0.0.0.0" if share else "127.0.0.1"
        )


def main():
    """Main function to launch the web interface"""
    
    # Check if model exists
    model_path = "./thai_slm_moe_model"
    
    if not os.path.exists(model_path):
        print("‚ö†Ô∏è Model not found!")
        print("Please train the model first by running: python train.py")
        print("Launching interface anyway for demonstration...")
    
    # Create and launch interface
    app = GradioInterface(model_path)
    app.launch(
        share=False,  # Set to True to create public link
        port=7860
    )


if __name__ == "__main__":
    main()
